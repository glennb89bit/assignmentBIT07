{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03793832-8067-4235-8185-ca1a35193b66",
   "metadata": {},
   "source": [
    "# Assignment Machine Learning\n",
    "***Assignment BIT07 / Bioinformatics @ home***\n",
    "\n",
    "**Student name**: Glenn Broeckx  \n",
    "**Student number**: 202054838"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918fac89-1e87-4fd2-85cb-78f8b05f65b5",
   "metadata": {},
   "source": [
    "## PART 1: Choosing the dataset\n",
    "For this assignment, a dataset on breast cancer characteristics, RNA expression and survival was chosen. This dataset is originating from the METABRIC clinical trials published in Nature (2012), wherein an European research group mapped genomic and transcriptomic profiles in breast cancer. (1)\n",
    "\n",
    "This dataset has a mixture of categorical variables (both ordinal and nominal) and numerical variables. It has the possibility to predict survival in both status as survival duration. Furhtermore, it is possible to predict the type of breast cancer based on gene expression profiling and gene mutational profiling, which was the main goal of the METABRIC clinical trial. \n",
    "\n",
    "The METABRIC dataset is freely available on the Kaggle website under the Database Contents License (DbCL) [v1.0] from following url: [https://www.kaggle.com/raghadalharbi/breast-cancer-gene-expression-profiles-metabric](https://www.kaggle.com/raghadalharbi/breast-cancer-gene-expression-profiles-metabric).\n",
    "\n",
    "In this Jupyter Notebook file, all modules, methods and functions will be imported. Several own created functions will be declared as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6b48f4-d725-4df9-90df-ae0dcd7c7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules, functions and methods\n",
    "###################################################\n",
    "# Data analysis and scientific calculations\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 20,8.27 #size of figures in inch\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, det_curve, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Own functies\n",
    "################\n",
    "def listdiff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif\n",
    "\n",
    "\n",
    "def ohe_and_bind(original_dataframe, features_to_encode):\n",
    "    if type(features_to_encode) is not list:\n",
    "        raise Exception(\"Features to encode needs to be a list\")\n",
    "\n",
    "    for f_encode in features_to_encode:\n",
    "        dummies = pd.get_dummies(original_dataframe[[f_encode]])\n",
    "        original_dataframe = original_dataframe.drop(f_encode, axis=1)\n",
    "        original_dataframe = pd.concat([original_dataframe, dummies], axis=1)\n",
    "\n",
    "    return(original_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b8bb6-a9a1-4592-a86f-2a2d6535f906",
   "metadata": {},
   "source": [
    "## PART 2: Describing the dataset\n",
    "The downloaded dataset is imported into a Pandas DataFrame, called `bc`, short for breast cancer. In this Notebook, variables derived from `bc` will further be named with a `bc_` prefix, followed by a short indication of derivation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ddf68a-42f5-4cc8-a93c-f42c7943468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (678,688,690,692) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_at_diagnosis</th>\n",
       "      <th>type_of_breast_surgery</th>\n",
       "      <th>cancer_type</th>\n",
       "      <th>cancer_type_detailed</th>\n",
       "      <th>cellularity</th>\n",
       "      <th>chemotherapy</th>\n",
       "      <th>pam50_+_claudin-low_subtype</th>\n",
       "      <th>cohort</th>\n",
       "      <th>er_status_measured_by_ihc</th>\n",
       "      <th>...</th>\n",
       "      <th>mtap_mut</th>\n",
       "      <th>ppp2cb_mut</th>\n",
       "      <th>smarcd1_mut</th>\n",
       "      <th>nras_mut</th>\n",
       "      <th>ndfip1_mut</th>\n",
       "      <th>hras_mut</th>\n",
       "      <th>prps2_mut</th>\n",
       "      <th>smarcb1_mut</th>\n",
       "      <th>stmn2_mut</th>\n",
       "      <th>siah1_mut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75.65</td>\n",
       "      <td>MASTECTOMY</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>claudin-low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43.19</td>\n",
       "      <td>BREAST CONSERVING</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>LumA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>48.87</td>\n",
       "      <td>MASTECTOMY</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>47.68</td>\n",
       "      <td>MASTECTOMY</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>76.97</td>\n",
       "      <td>MASTECTOMY</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 693 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  age_at_diagnosis type_of_breast_surgery    cancer_type  \\\n",
       "0           0             75.65             MASTECTOMY  Breast Cancer   \n",
       "1           2             43.19      BREAST CONSERVING  Breast Cancer   \n",
       "2           5             48.87             MASTECTOMY  Breast Cancer   \n",
       "3           6             47.68             MASTECTOMY  Breast Cancer   \n",
       "4           8             76.97             MASTECTOMY  Breast Cancer   \n",
       "\n",
       "                        cancer_type_detailed cellularity  chemotherapy  \\\n",
       "0           Breast Invasive Ductal Carcinoma         NaN             0   \n",
       "1           Breast Invasive Ductal Carcinoma        High             0   \n",
       "2           Breast Invasive Ductal Carcinoma        High             1   \n",
       "3  Breast Mixed Ductal and Lobular Carcinoma    Moderate             1   \n",
       "4  Breast Mixed Ductal and Lobular Carcinoma        High             1   \n",
       "\n",
       "  pam50_+_claudin-low_subtype  cohort er_status_measured_by_ihc  ... mtap_mut  \\\n",
       "0                 claudin-low     1.0                   Positve  ...        0   \n",
       "1                        LumA     1.0                   Positve  ...        0   \n",
       "2                        LumB     1.0                   Positve  ...        0   \n",
       "3                        LumB     1.0                   Positve  ...        0   \n",
       "4                        LumB     1.0                   Positve  ...        0   \n",
       "\n",
       "   ppp2cb_mut smarcd1_mut nras_mut ndfip1_mut  hras_mut prps2_mut smarcb1_mut  \\\n",
       "0           0           0        0          0         0         0           0   \n",
       "1           0           0        0          0         0         0           0   \n",
       "2           0           0        0          0         0         0           0   \n",
       "3           0           0        0          0         0         0           0   \n",
       "4           0           0        0          0         0         0           0   \n",
       "\n",
       "  stmn2_mut  siah1_mut  \n",
       "0         0          0  \n",
       "1         0          0  \n",
       "2         0          0  \n",
       "3         0          0  \n",
       "4         0          0  \n",
       "\n",
       "[5 rows x 693 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1: Importing dataset\n",
    "bc = pd.read_csv('METABRIC_RNA_Mutation.csv')\n",
    "bc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13e3a92c-1b0e-436f-935a-eca0b933cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows/observations/patients in the dataframe:\t 1904\n",
      "Number of columns/features/attributes in the dataframe:\t  693\n"
     ]
    }
   ],
   "source": [
    "bc_shape = bc.shape\n",
    "print(f'Number of rows/observations/patients in the dataframe:\\t{bc_shape[0]:5d}')\n",
    "print(f'Number of columns/features/attributes in the dataframe:\\t{bc_shape[1]:5d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eae97-f231-4e6c-ba74-03a18fae1195",
   "metadata": {},
   "source": [
    "The `head()` method defaulty shows the first 5 rows of the dataframe. It is followed with the dimensions of the shown dataframe, But because only the head method is used, the number of observations/rows was limited to 5. The `shape` method gives a better overview of the overall dimensions of the dataframe. As presented in the output of previous code cell, these are the dimensions:\n",
    "\n",
    "- Number of rows/observations/patients in the dataframe: 1904\n",
    "- Number of columns/features/attributes in the dataframe: 693"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f17856-e6d8-4b74-bc6b-61843f0cfe14",
   "metadata": {},
   "source": [
    "## 2.1 Describing the attributes\n",
    "As previously discussed, 693 attributes are present in this dataset. These are quite a lot to individually discuss them in a table. The high number of attributes is caused by the genomic and transcriptomic mapping, in which each gene has its own attribute. Transcriptomic mapping starts at column with name `brca1`, genomics mapping starts at column with name `pik3ca_mut`. In the next cell, the indices of thise columns are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996230a5-f59d-4e3f-80d1-9fc63e5d64d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting index of transcriptomics (starting at brca1:\t   31\n",
      "Starting index of genomics (starting at pik3ca_mut:\t  520\n"
     ]
    }
   ],
   "source": [
    "print(f'Starting index of transcriptomics (starting at brca1:\\t{bc.columns.get_loc(\"brca1\"):5d}')\n",
    "print(f'Starting index of genomics (starting at pik3ca_mut:\\t{bc.columns.get_loc(\"pik3ca_mut\"):5d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0facc94f-faa8-406d-8b7b-8d3ccc2d841b",
   "metadata": {},
   "source": [
    "In following overview, all attributes concerning transcriptomics (columns with index 31 to 519) and all attributes concerning genomics (columns with index 520 to 692) are lumped together for readability.\n",
    "\n",
    "The following overview is based on information from the Kaggle website and from the METABRIC publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655a7c4-24b2-47d8-91d2-03da47225560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 1.2: beschrijven van de dataset\n",
    "df.shape #dimensies van de dataset\n",
    "df.describe() # range van waarden; vul ook aan met info over kolommen van bron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f42a9f-1782-41e2-81f5-5251390b51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 1.3: Zoeken naar missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fb1f8-61bb-4318-8cca-d45df7a3bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 1.4: Zoeken naar inconsistente\n",
    "df.describe() # range van waarden kloppen met mogelijke werkelijkheid? Te veel nullen als missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d912e9-2cf6-489e-81df-a0f55989ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 1.5: Zoeken naar uitschieters\n",
    "columns = df.columns()\n",
    "\n",
    "for column in columns:\n",
    "    ax1 = sns.boxplot(x=column, data=df) #interessanter voor categorische data\n",
    "    ax2 = sns.histplot(x=column, data=df) #beter voor numerieke data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e0b7b-0976-4c5f-a9ee-bd362f3ae8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 1.6: Verwijderen van data\n",
    "df.drop('column', axis=1, inplace=True) #kolom verwijderen wegens niet contributief of missing values\n",
    "df.drop(df[(df.column1 == 0) | (df.column2 == 0) | (df.column3 == 0)].index, inplace = True) #Rijen verwijderen met foutieve waarde 0\n",
    "df = df[(np.abs(stats.zscore(df)) < 5).all(axis=1)] #Verwijderen van uitschieters die meer dan 5x SD verwijderd zijn van gemiddelde\n",
    "df = df.dropna() #Verwijderen van rijen met missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c900bad-8fb4-4c2b-bd64-1498e14b3428",
   "metadata": {},
   "source": [
    "### Conclusie stap 1\n",
    "Deze dataset bestaat uit volgende kolommen (+info):\n",
    "- Kolom 1: info\n",
    "- Kolom 2: info\n",
    "- ...\n",
    "\n",
    "Er zijn X observaties en Y kolommen. Hierin zijn er A vreemde waarden/missing values. Deze worden verwijderd/behouden/omvormd. Omvormen (imputing) kan pas na het splitsen van de dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d81e-e5e3-4a05-8c92-7150e56f36d7",
   "metadata": {},
   "source": [
    "## Stap 2: Analyse en preprocessing\n",
    "**Stap 2.1: analyse**  \n",
    "Bij de analytische fase is het de bedoeling om te kijken naar welke features een invloed hebben op het target. Dit kan op volgende manieren:\n",
    "- Pairplot (moeilijk leesbaar bij veel features --> exporteren en zoomen)\n",
    "- Heatmap (moeilijk leesbaar bij veel features --> exporteren en zoomen)\n",
    "- Afzonderlijke scatterplots\n",
    "- Boxplots van categorieke features\n",
    "- Gebalanceerdheid van de data\n",
    "\n",
    "Creativiteit de vrije loop laten gaan!\n",
    "\n",
    "**Stap 2.2 preprocessing**  \n",
    "Voor het preprocessen zijn er verschillende stappen te ondergaan:\n",
    "1. Omvormen van ordinale categorieÃ«n (ordinal encoding)\n",
    "2. Omvormen van categorische waarden (one-hot encoding)\n",
    "3. Opsplitsen in features en targets\n",
    "4. Opsplitsen in testset en trainingsset\n",
    "4. Omvormen van missing values (imputing)\n",
    "5. Schalen van numerieke features\n",
    "\n",
    "Bij elke stap laten weten op welke manier en waarom je dit doet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb651ad7-fe65-4739-af91-8336cdd3698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.1.1: Pairplot\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45930b81-6902-471d-88fa-4599f5378028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.1.2 Heatmap\n",
    "df_corr = df.corr()\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(df_corr, \n",
    "            mask=np.zeros_like(df_corr, dtype=bool), \n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, \n",
    "            ax=ax,annot=True\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8dc21-287b-4622-bd30-d3b38e0e7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.1.3: Afzonderlijke scatterplots\n",
    "sns.scatterplot(data=df, x='feature', y='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b06dcf-c6c3-4960-834e-15d564067a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.1.4: Boxplots van categorieke waarden\n",
    "sns.boxplot(x=df[\"feature\"], y=df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878008bd-1c9a-4028-be48-983985547229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.1.5: Gebalanceerdheid van de data op basis van target\n",
    "df['target'].value_counts() #absolute waarden\n",
    "df['target'].value_counts(normalize=True) #percentages\n",
    "sns.countplot(x=\"target\", data=df) #histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55200212-a2a5-4208-94b7-566340c7f4f2",
   "metadata": {},
   "source": [
    "### Conclusie stap 2.1\n",
    "Formuleer enkele bevindingen van de data-analyse. Kopieer deze ook al naar de eindconclusie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208b39e-d8d1-4f0c-b04b-6d21f6817938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.2.1: Omvormen ordinale categorieÃ«n: rankings naar nummers\n",
    "cat1 = ['rank1', 'rank2', 'rank3'] # categoriesleutel op basis van de vooranalyse voor feature 1\n",
    "cat2 = ['rank1', 'rank2', 'rank3'] # categoriesleutel op basis van de vooranalyse voor feature 2\n",
    "\n",
    "ord_features = ['feature1', 'feature2'] # lijst met alle colomnamen met ordinale features\n",
    "rest_features = listdiff(df.columns, ord_features)\n",
    "\n",
    "ordinal_trf = ColumnTransformer(\n",
    "    transformers =[\n",
    "        ('ord', #gewoon een naam\n",
    "         preprocessing.OrdinalEncoder(categories=[cat1, cat2]), # Belangrijk!: er moeten evenveel categorieÃ«n zijn als aantal om te zetten features. Deze moeten in volgorde staan en als twee features zelfde categorieÃ«n hebben mag dit herhaald worden\n",
    "         ord_features), #Lijst met de features om te transformeren\n",
    "], remainder ='passthrough')\n",
    "\n",
    "df = pd.DataFrame(ordinal_trf.fit_transform(df), columns=[ord_features, rest_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78215b6-4e2a-4b51-8c71-ccb9660826b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.2.2: One-hot encoding\n",
    "ohe_features = [featureA, featureB]\n",
    "df = ohe_and_bind(df, ohe_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f80b8f-dd68-4447-b9fa-77da0ac208f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.2.3: Opsplitsen in features en target\n",
    "y = df['target'].values.astype('int')\n",
    "X = pd.DataFrame(df.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e59a7f-c0ab-4826-bff1-78716f7a0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.2.4: Opsplitsen in training en testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c84221-f96f-49e0-b201-6ef653f9d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.2.5: Imputing (kan wegvallen indien niet nodig)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') # of andere strategie\n",
    "imp.fit(X_train)\n",
    "\n",
    "imp.transform(X_train)\n",
    "X_train = pd.DataFram(X_train, columns=imp.feature_names_in_)\n",
    "imp.transform(X_test)\n",
    "X_test = pd.DataFram(X_test, columns=imp.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4da5e-c63d-489a-a592-4bebf4a346b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 2.2.6: Schaling (moet gebeuren!)\n",
    "scaler = StandardScaler() # of andere schaler\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932a953-608d-4186-b552-3add306ff28b",
   "metadata": {},
   "source": [
    "### Conclusie stap 2.2\n",
    "Maak een conclusie over alle preprocessing eventueel met vermelding van het aantal features nu. Ook altijd vermelden waarom je voor welke techniek hebt gekozen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4e416-6b80-4ae9-84e8-a85401a6b281",
   "metadata": {},
   "source": [
    "## Stap 3: Regressie\n",
    "Gebruik lineaire regressie om een conintue variabele target te voorspellen.\n",
    "\n",
    "Stappenplan:\n",
    "1. Initieel model zonder tweaking\n",
    "2. Initieel model beoordelen (MSE, MAE en RÂ²)\n",
    "3. Model tunen\n",
    "    1. Nieuwe features creÃ«ren\n",
    "    2. Polynomiale expansie\n",
    "    3. Regularisatie\n",
    "    4. Hyperparameter tuning: Grid search/Random search\n",
    "4. Model selecteren op basis van Grid search\n",
    "5. Finaal model evalueren\n",
    "\n",
    "Het is moeilijk om hier voorbeeldcode te geven. Dit moet bijna altijd worden aangepast aan de situatie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197be56-bf12-4a9f-b5e4-8c670aafab22",
   "metadata": {},
   "source": [
    "## Stap 4: Classificatie\n",
    "Gebruik Logistische regressie, SVM om een categorieke variabele target te voorspellen.\n",
    "\n",
    "Stappenplan (zelfde als bij lineaire regressie, maar meerdere type modellen te testen bij Grid search):\n",
    "1. Initieel model zonder tweaking\n",
    "2. Initieel model beoordelen (Precisie, Recall, Accuracy, Confusiematrix, ROC en AUC)\n",
    "3. Model tunen\n",
    "    1. Nieuwe features creÃ«ren\n",
    "    2. Polynomiale expansie\n",
    "    3. Regularisatie\n",
    "    4. Hyperparameter tuning: Grid search/Random search\n",
    "4. Model selecteren op basis van Grid search\n",
    "5. Finaal model evalueren\n",
    "\n",
    "Het is moeilijk om hier voorbeeldcode te geven. Dit moet bijna altijd worden aangepast aan de situatie. Bij Classificatie is het altijd leuk om de ROC curves te tekenen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301f95f-43f2-477c-b08d-c91d8a46f3fc",
   "metadata": {},
   "source": [
    "## Stap 5: Clustering\n",
    "Gebruik een clustering methode om een cluster te voorspellen.\n",
    "\n",
    "Stappenplan (zelfde als bij lineaire regressie, maar meerdere type modellen te testen bij Grid search):\n",
    "1. Initieel model zonder tweaking\n",
    "2. Initieel model beoordelen (nog op te zoeken: evaluatieparameters)\n",
    "3. Model tunen\n",
    "    1. Nieuwe features creÃ«ren\n",
    "    2. Polynomiale expansie\n",
    "    3. Regularisatie\n",
    "    4. Hyperparameter tuning: Grid search/Random search (? geen idee of dit past)\n",
    "4. Model selecteren op basis van Grid search\n",
    "5. Finaal model evalueren\n",
    "\n",
    "Het is moeilijk om hier voorbeeldcode te geven. Dit moet bijna altijd worden aangepast aan de situatie. We moeten blijkbaar niet alle attributen gebruiken in het model. We mogen ons beperken tot de attributen met een goede performance of een combinatie van verschillende goede attributen. We moeten het wel proberen te baseren op dezelfde attributen als bij classificatie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de8f74-0599-4ceb-a936-93fc34b32b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap x.1: Initieel model\n",
    "model = module.Methode(parameters) # Aan te passen voor het type model je wilt gebruiken\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "## Voorbeelden modellen:\n",
    "lregmodel = linear_model.LinearRegression()\n",
    "ridgemodel = linear_model.Ridge(alpha=alpha,tol=0.0001,fit_intercept=True) # L2 regularisatie\n",
    "lasso = linear_model.Lasso(alpha=alpha,tol=0.0001,fit_intercept=True) # L1 regularisatie\n",
    "logrmodel = linear_model.LogisticRegression(C=1, solver='liblinear', class_weight='balanced', multi_class='ovr')\n",
    "svmmodel = svm.SVC(kernel='linear',C=0.01)\n",
    "# Wordt nog verder aangevuld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ff9d7-e384-40e3-a423-057c23c2a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap x.2: Model beoordelen\n",
    "## Linear, Ridge en Lasso\n",
    "r2train = lregmodel.score(X_train, y_train)\n",
    "r2test = lregmodel.score(X_test, y_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "## Logistic en SVM\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "## Clustering\n",
    "# Wordt nog aangevuld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53de9e-9805-4d1a-8d09-17cd94473fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap x.3: Model tunen (werk opnieuw vanaf de basisset)\n",
    "## x.3.1: Nieuwe features creÃ«ren\n",
    "df.insert(df.columns.size-1, 'new_feature', df.feature1*df.feature2) # kan ook som, min, deling\n",
    "\n",
    "\n",
    "## x.3.2: Polynomiale expansie\n",
    "pol = df[['lijst met features met continue variabelen']]\n",
    "nopol = lego.drop(['lijst met features met continue variabelen'], axis=1)\n",
    "\n",
    "graad = 4 \n",
    "\n",
    "poly = PolynomialFeatures(graad)\n",
    "poly.fit(pol)\n",
    "polynom = pd.DataFrame(poly.transform(pol), columns=poly.get_feature_names_out(pol.columns))\n",
    "\n",
    "### Belangrijk! vul aan met One-hot encoding en ordinal encoding indien nodig, daarna opnieuw opsplitsen\n",
    "ord_features = ['feature1', 'feature2'] # lijst met alle colomnamen met ordinale features\n",
    "rest_features = listdiff(df.columns, ord_features)\n",
    "nopol = pd.DataFrame(ordinal_trf.fit_transform(nopol), columns=[ord_features, rest_features])\n",
    "\n",
    "ohe_features = [featureA, featureB]\n",
    "nopol = ohe_and_bind(nopol, ohe_features)\n",
    "\n",
    "df_preprocessed = pd.concat([polynom, nopol], axis=1)\n",
    "\n",
    "y = df_preprocessed['target'].values.astype('int')\n",
    "X = pd.DataFrame(df_preprocessed.drop('target', axis=1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, random_state=0)\n",
    "\n",
    "\n",
    "## X.3.3: Regularisatie (kan ook tijdens gridsearch)\n",
    "### Linear regression --> gebruik Lasso of Ridge regressie\n",
    "### Logistic regression --> standaard is L2\n",
    "lr = linear_model.LogisticRegression(C=1, solver='liblinear', class_weight='balanced', penalty='l1')\n",
    "### SVM heeft geen regularisatie maar wel kernels\n",
    "svmmodel = svm.SVC(kernel='poly',C=10000000)\n",
    "\n",
    "\n",
    "## X.3.4: Hyperparameter tuning met grid search of random search\n",
    "### linear regression alleen bij ridge/lasso en weinig zin\n",
    "lrparam = {'alpha' = np.logspace(-5, 4, 10)}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = lrparam,\n",
    "                           scoring = 'r2', # roc_auc, f1_weighted, f1_macro, recall, ...\n",
    "                           cv = 15,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 5)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "y_pred = grid_search.predict(X_test)\n",
    "r2train = lregmodel.score(X_train, y_train)\n",
    "r2test = lregmodel.score(X_test, y_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "### logistic regression grid search\n",
    "logrparam = {\n",
    "    'solver' = ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty' = ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C' = np.logspace(-5, 4, 10)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = logrparam,\n",
    "                           scoring = 'accuracy', # roc_auc, f1_weighted, f1_macro, recall, ...\n",
    "                           cv = 15,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 5)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "y_pred = grid_search.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "### logistic regression random search\n",
    "logrparam = {\n",
    "    'solver' = ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty' = ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C' = loguniform(1e-5, 100)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, \n",
    "                                   logrparam, \n",
    "                                   n_iter=20, \n",
    "                                   scoring='accuracy', \n",
    "                                   n_jobs=-1, \n",
    "                                   cv=5, \n",
    "                                   random_state=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "y_pred = random_search.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "### SVM grid search\n",
    "svmparamaters = [ \n",
    "        {'kernel': ['linear'], 'C': np.linspace(0.01,20,10)},\n",
    "        {'kernel': ['rbf'], 'C': np.linspace(0.01,20,10), 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2]},\n",
    "        {'kernel': ['poly'], 'C':np.linspace(0.01,20,10)} ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = svmparamaters,\n",
    "                           scoring = 'accuracy', # roc_auc, f1_weighted, f1_macro, recall, ...\n",
    "                           cv = 15,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 5)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_ \n",
    "best_parameters = grid_search.best_params_  \n",
    "y_pred = grid_search.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "### SVM random search\n",
    "model = SVC(probability=True)\n",
    "parameters = {'kernel': ['linear','rbf','poly'],\n",
    "              'C': uniform(0.01, 20), # haal C uit een random uniform distribution\n",
    "              'gamma': uniform(0.001, 0.2)}\n",
    "\n",
    "\n",
    "n_iter_search = 20\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
    "\n",
    "random_search = random_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = random_search.best_score_ \n",
    "best_parameters = random_search.best_params_  \n",
    "y_pred = random_search.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#### Nog aan te vullen voor clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a19ec-38a6-4f59-8983-8f680515ad25",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Conclusie schrijven over:\n",
    "- Dataset\n",
    "    - Goed/slecht en waarom?\n",
    "    - Problemen in de dataset\n",
    "- Model\n",
    "    - Beste model voor elke techniek\n",
    "    - Performance\n",
    "    - Overfitting/underfitting\n",
    "    - Kan gebruikt worden in dagdagelijkse praktijk?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4f63f-0bbf-448f-8a59-8869698a53c9",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Curtis, C., Shah, S.P., Chin, S.-F., Turashvili, G., Rueda, O.M., Dunning, M.J., Speed, D., Lynch, A.G., Samarajiwa, S., Yuan, Y., GrÃ¤f, S., Ha, G., Haffari, G., Bashashati, A., Russell, R., Mckinney, S., LangerÃ¸d, A., Green, A., Provenzano, E., Wishart, G., Pinder, S., Watson, P., Markowetz, F., Murphy, L., Ellis, I., Purushotham, A., BÃ¸rresen-Dale, A.-L., Brenton, J.D., TavarÃ©, S., Caldas, C., Aparicio, S., 2012. The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups. Nature 486, 346â€“352.. doi:10.1038/nature10983"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
